# Paper Summaries

A personal collection of summaries from research papers I'm reading, especially in NLP and Deep Learning.

---

## ðŸ“„ Latest Summary

- [Attention Is All You Need](Attention-Is-All-You-Need.md)  
  Summary of the original Transformer paper by Vaswani et al., 2017 (NeurIPS). Introduces the attention-based architecture that powers modern language models like BERT and GPT.

-  (WIP) [BERT](BERT.md)


---

More coming soon...
